import streamlit as st
import json
import base64
import urllib.parse
import os
import requests  # æ–°å¢ï¼šç”¨äºè¯·æ±‚ç½‘ç»œé“¾æ¥


# ================= æ ¸å¿ƒå¤„ç†é€»è¾‘ (ä¿æŒä¸å˜) =================

def safe_base64_decode(s):
    """
    ç”¨äºè§£æ vmess:// åé¢çš„ base64 å­—ç¬¦ä¸²
    """
    s = s.strip()
    missing_padding = len(s) % 4
    if missing_padding:
        s += '=' * (4 - missing_padding)
    return base64.urlsafe_b64decode(s).decode('utf-8')


def parse_vmess(url_body):
    try:
        json_str = safe_base64_decode(url_body)
        data = json.loads(json_str)
        proxy = {
            "name": data.get("ps", "vmess"),
            "type": "vmess",
            "server": data.get("add"),
            "port": int(data.get("port")),
            "uuid": data.get("id"),
            "alterId": int(data.get("aid", 0)),
            "cipher": data.get("scy", "auto"),
            "network": data.get("net", "ws"),
            "tls": True if data.get("tls") else False,
            "udp": True,
            "skip-cert-verify": True if data.get("verify_cert") == False else False
        }
        if proxy["network"] == "ws":
            proxy["ws-opts"] = {
                "path": data.get("path", "/"),
                "headers": {"Host": data.get("host", data.get("add"))}
            }
        return proxy
    except Exception:
        return None


def parse_vless(parsed_url):
    params = urllib.parse.parse_qs(parsed_url.query)
    network = params.get("type", ["tcp"])[0]
    proxy = {
        "name": urllib.parse.unquote(parsed_url.fragment),
        "type": "vless",
        "server": parsed_url.hostname,
        "port": parsed_url.port,
        "uuid": parsed_url.username,
        "udp": True,
        "tls": True,
        "network": network,
        "servername": params.get("sni", [""])[0],
        "skip-cert-verify": True if params.get("allowInsecure", ["0"])[0] == "1" else False,
    }
    if network == "ws":
        host = params.get("host", [""])[0]
        if not host: host = proxy["servername"] or proxy["server"]
        proxy["ws-opts"] = {
            "path": params.get("path", ["/"])[0],
            "headers": {"Host": host}
        }
    if network == "tcp":
        flow = params.get("flow", [""])[0]
        if flow: proxy["flow"] = flow
    if "fp" in params:
        proxy["client-fingerprint"] = params["fp"][0]
    else:
        proxy["client-fingerprint"] = "chrome"
    if params.get("security", [""])[0] == "reality":
        proxy["reality-opts"] = {"public-key": params.get("pbk", [""])[0]}
        sid = params.get("sid", params.get("shortId", params.get("short-id", [])))
        if sid: proxy["reality-opts"]["short-id"] = sid[0]
        if not proxy["servername"]: proxy["servername"] = params.get("sni", [""])[0]
    return proxy


def parse_hysteria2(parsed_url):
    params = urllib.parse.parse_qs(parsed_url.query)
    return {
        "name": urllib.parse.unquote(parsed_url.fragment),
        "type": "hysteria2",
        "server": parsed_url.hostname,
        "port": parsed_url.port,
        "password": parsed_url.username,
        "sni": params.get("sni", [""])[0],
        "skip-cert-verify": True if params.get("insecure", ["0"])[0] == "1" else False,
        "udp": True
    }


def parse_tuic(parsed_url):
    params = urllib.parse.parse_qs(parsed_url.query)
    user_info = parsed_url.username.split(':') if parsed_url.username else ["", ""]
    proxy = {
        "name": urllib.parse.unquote(parsed_url.fragment),
        "type": "tuic",
        "server": parsed_url.hostname,
        "port": parsed_url.port,
        "uuid": user_info[0],
        "password": user_info[1] if len(user_info) > 1 else "",
        "sni": params.get("sni", [""])[0],
        "udp-relay-mode": "native",
        "congestion-controller": params.get("congestion_control", ["bbr"])[0],
        "skip-cert-verify": True if params.get("insecure", ["0"])[0] == "1" else False,
        "disable-sni": True,
        "udp": True
    }
    if "alpn" in params: proxy["alpn"] = [params["alpn"][0]]
    return proxy


def generate_yaml(proxies, rules_content):
    proxy_names = [p['name'] for p in proxies]
    yaml_content = """mixed-port: 7890
allow-lan: true
mode: Rule
log-level: info
external-controller: :9090
proxies:
"""
    for p in proxies:
        yaml_content += f"  - name: {p['name']}\n"
        yaml_content += f"    type: {p['type']}\n"
        yaml_content += f"    server: {p['server']}\n"
        yaml_content += f"    port: {p['port']}\n"

        for key in ["uuid", "password", "udp", "tls", "flow", "servername", "sni", "client-fingerprint", "network",
                    "alterId", "cipher", "skip-cert-verify", "udp-relay-mode", "congestion-controller", "disable-sni"]:
            if key in p:
                val = str(p[key]).lower() if isinstance(p[key], bool) else p[key]
                yaml_content += f"    {key}: {val}\n"

        if "ws-opts" in p:
            yaml_content += f"    ws-opts:\n      path: {p['ws-opts']['path']}\n      headers:\n        Host: {p['ws-opts']['headers']['Host']}\n"
        if "reality-opts" in p:
            yaml_content += f"    reality-opts:\n      public-key: {p['reality-opts']['public-key']}\n"
            if "short-id" in p['reality-opts']: yaml_content += f"      short-id: {p['reality-opts']['short-id']}\n"
        if "alpn" in p:
            yaml_content += f"    alpn:\n"
            for a in p['alpn']: yaml_content += f"      - {a}\n"

    yaml_content += "proxy-groups:\n"
    groups = [
        {"name": "ğŸš€ èŠ‚ç‚¹é€‰æ‹©", "type": "select", "special": ["â™»ï¸ è‡ªåŠ¨é€‰æ‹©", "DIRECT"]},
        {"name": "â™»ï¸ è‡ªåŠ¨é€‰æ‹©", "type": "url-test", "url": "http://www.gstatic.com/generate_204", "interval": 300,
         "tolerance": 50, "special": []},
        {"name": "ğŸŒ å›½å¤–åª’ä½“", "type": "select", "special": ["ğŸš€ èŠ‚ç‚¹é€‰æ‹©", "â™»ï¸ è‡ªåŠ¨é€‰æ‹©", "ğŸ¯ å…¨çƒç›´è¿"]},
        {"name": "ğŸ“² ç”µæŠ¥ä¿¡æ¯", "type": "select", "special": ["ğŸš€ èŠ‚ç‚¹é€‰æ‹©", "ğŸ¯ å…¨çƒç›´è¿"]},
        {"name": "â“‚ï¸ å¾®è½¯æœåŠ¡", "type": "select", "special": ["ğŸ¯ å…¨çƒç›´è¿", "ğŸš€ èŠ‚ç‚¹é€‰æ‹©"]},
        {"name": "ğŸ è‹¹æœæœåŠ¡", "type": "select", "special": ["ğŸš€ èŠ‚ç‚¹é€‰æ‹©", "ğŸ¯ å…¨çƒç›´è¿"]},
        {"name": "ğŸ“¢ è°·æ­ŒFCM", "type": "select", "special": ["ğŸš€ èŠ‚ç‚¹é€‰æ‹©", "ğŸ¯ å…¨çƒç›´è¿", "â™»ï¸ è‡ªåŠ¨é€‰æ‹©"]},
        {"name": "ğŸ¯ å…¨çƒç›´è¿", "type": "select", "base": ["DIRECT", "ğŸš€ èŠ‚ç‚¹é€‰æ‹©", "â™»ï¸ è‡ªåŠ¨é€‰æ‹©"], "no_proxies": True},
        {"name": "ğŸ›‘ å…¨çƒæ‹¦æˆª", "type": "select", "base": ["REJECT", "DIRECT"], "no_proxies": True},
        {"name": "ğŸƒ åº”ç”¨å‡€åŒ–", "type": "select", "base": ["REJECT", "DIRECT"], "no_proxies": True},
        {"name": "ğŸŸ æ¼ç½‘ä¹‹é±¼", "type": "select", "special": ["ğŸš€ èŠ‚ç‚¹é€‰æ‹©", "ğŸ¯ å…¨çƒç›´è¿", "â™»ï¸ è‡ªåŠ¨é€‰æ‹©"]},
    ]

    for g in groups:
        yaml_content += f"  - name: {g['name']}\n    type: {g['type']}\n"
        if "url" in g: yaml_content += f"    url: {g['url']}\n    interval: {g['interval']}\n    tolerance: {g['tolerance']}\n"
        yaml_content += f"    proxies:\n"
        if "base" in g:
            for b in g["base"]: yaml_content += f"      - {b}\n"
        if "special" in g:
            for s in g["special"]: yaml_content += f"      - {s}\n"
        if not g.get("no_proxies", False):
            for name in proxy_names: yaml_content += f"      - {name}\n"

    yaml_content += "rules:\n" + rules_content
    return yaml_content


# ================= ç½‘é¡µç•Œé¢é€»è¾‘ =================

st.set_page_config(page_title="V2Ray è½¬ Clash", page_icon="ğŸ”„")

st.title("ğŸ”„ V2Ray é“¾æ¥è½¬ Clash Meta é…ç½®")
st.markdown("ä¸Šä¼ ä½ çš„èŠ‚ç‚¹åˆ—è¡¨æ–‡ä»¶ï¼Œæˆ–è€…ç›´æ¥è¾“å…¥è®¢é˜…é“¾æ¥ã€‚")

# å¸ƒå±€ï¼šæ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
col1, col2 = st.columns(2)
with col1:
    nodes_file = st.file_uploader("1. ä¸Šä¼ èŠ‚ç‚¹æ–‡ä»¶ (txt)", type=['txt'], help="æ¯è¡Œä¸€ä¸ª vmess/vless é“¾æ¥")
with col2:
    rules_file = st.file_uploader("2. ä¸Šä¼ è§„åˆ™æ–‡ä»¶ (å¯é€‰)", type=['txt'], help="ç•™ç©ºåˆ™è¯»å–æœåŠ¡å™¨æœ¬åœ° rules.txt")

# æ–°å¢ï¼šè®¢é˜…é“¾æ¥è¾“å…¥æ¡†
subscription_url = st.text_input("ğŸ”— æˆ–è€…è¾“å…¥è®¢é˜…é“¾æ¥ (URL)", placeholder="https://example.com/subscribe?token=...",
                                 help="è¾“å…¥æœºåœºæˆ–é¢æ¿çš„è®¢é˜…é“¾æ¥ï¼Œè‡ªåŠ¨æŠ“å–å¹¶ Base64 è§£ç ")

# å¤‡ç”¨æç®€è§„åˆ™
fallback_rules = """  - GEOIP,CN,ğŸ¯ å…¨çƒç›´è¿
  - MATCH,ğŸŸ æ¼ç½‘ä¹‹é±¼
"""

if st.button("å¼€å§‹è½¬æ¢", type="primary"):
    nodes_content = ""

    # === 1. è·å–èŠ‚ç‚¹å†…å®¹ (ä¼˜å…ˆå¤„ç†è®¢é˜…é“¾æ¥) ===
    if subscription_url:
        try:
            with st.spinner("ğŸš€ æ­£åœ¨è¯·æ±‚è®¢é˜…æ•°æ®..."):
                # æ¨¡æ‹Ÿæµè§ˆå™¨ User-Agentï¼Œé˜²æ­¢éƒ¨åˆ†æœºåœºæ‹¦æˆª Python è¯·æ±‚
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'}
                resp = requests.get(subscription_url.strip(), headers=headers, timeout=15)
                resp.raise_for_status()
                raw_content = resp.text.strip()

                # Base64 è§£ç é€»è¾‘
                try:
                    # è‡ªåŠ¨è¡¥å…¨ Base64 ç¼ºå¤±çš„ Padding
                    missing_padding = len(raw_content) % 4
                    if missing_padding:
                        raw_content += '=' * (4 - missing_padding)

                    # å°è¯•æ ‡å‡†è§£ç 
                    nodes_content = base64.b64decode(raw_content).decode('utf-8')
                except Exception as e:
                    # å¦‚æœæ ‡å‡†è§£ç å¤±è´¥ï¼Œå°è¯• URL-safe è§£ç ï¼Œæˆ–ç›´æ¥å‡è®¾æ˜¯æ˜æ–‡
                    try:
                        nodes_content = base64.urlsafe_b64decode(raw_content).decode('utf-8')
                    except Exception:
                        # æ—¢ä¸æ˜¯æ ‡å‡†Base64ä¹Ÿä¸æ˜¯URLSafeBase64ï¼Œå¯èƒ½ç›´æ¥æ˜¯æ˜æ–‡åˆ—è¡¨
                        nodes_content = raw_content
                        st.warning("âš ï¸ å†…å®¹ä¼¼ä¹ä¸æ˜¯ Base64 ç¼–ç ï¼Œå°è¯•ç›´æ¥è§£æ...")

                st.success("âœ… è®¢é˜…è·å–å¹¶è§£ææˆåŠŸï¼")
        except Exception as e:
            st.error(f"âŒ è·å–è®¢é˜…å¤±è´¥: {e}")
            st.stop()

    # === 2. å¦‚æœæ²¡è¾“é“¾æ¥ï¼Œæ£€æŸ¥ä¸Šä¼ çš„æ–‡ä»¶ ===
    elif nodes_file:
        nodes_content = nodes_file.getvalue().decode("utf-8")

    else:
        st.error("è¯·ä¸Šä¼ èŠ‚ç‚¹æ–‡ä»¶æˆ–è¾“å…¥è®¢é˜…é“¾æ¥ï¼")
        st.stop()

    # === 3. è§„åˆ™æ–‡ä»¶åŠ è½½é€»è¾‘ ===
    if rules_file:
        rules_content = rules_file.getvalue().decode("utf-8")
        st.success("å·²ä½¿ç”¨æ‚¨ä¸Šä¼ çš„è§„åˆ™æ–‡ä»¶ã€‚")
    elif os.path.exists('rules.txt'):
        try:
            with open('rules.txt', 'r', encoding='utf-8') as f:
                rules_content = f.read()
            st.info("æ£€æµ‹åˆ°æœªä¸Šä¼ è§„åˆ™ï¼Œå·²è‡ªåŠ¨åŠ è½½æœåŠ¡å™¨æœ¬åœ° rules.txtã€‚")
        except Exception as e:
            st.error(f"æœ¬åœ° rules.txt è¯»å–å¤±è´¥: {e}")
            rules_content = fallback_rules
    else:
        st.warning("âš ï¸ æœªä¸Šä¼ è§„åˆ™æ–‡ä»¶ï¼Œä¸”æœåŠ¡å™¨æœ¬åœ°æœªæ‰¾åˆ° rules.txtï¼Œå°†ä½¿ç”¨å†…ç½®æç®€è§„åˆ™ã€‚")
        rules_content = fallback_rules

    # === 4. å¤„ç†èŠ‚ç‚¹è§£æ ===
    proxies = []
    name_counter = {}

    for line in nodes_content.splitlines():
        line = line.strip()
        if not line: continue
        p = None
        try:
            if line.startswith("vmess://"):
                p = parse_vmess(line[8:])
            elif line.startswith("vless://"):
                p = parse_vless(urllib.parse.urlparse(line))
            elif line.startswith("hysteria2://"):
                p = parse_hysteria2(urllib.parse.urlparse(line))
            elif line.startswith("tuic://"):
                p = parse_tuic(urllib.parse.urlparse(line))

            if p:
                # é‡åæ£€æµ‹
                original_name = p['name']
                if original_name in name_counter:
                    name_counter[original_name] += 1
                    p['name'] = f"{original_name}_{name_counter[original_name]}"
                else:
                    name_counter[original_name] = 0

                proxies.append(p)
        except Exception:
            continue

    if not proxies:
        st.error("âŒ æœªèƒ½è¯†åˆ«åˆ°æœ‰æ•ˆçš„èŠ‚ç‚¹é“¾æ¥ï¼Œè¯·æ£€æŸ¥è®¢é˜…å†…å®¹æˆ–æ–‡ä»¶ã€‚")
    else:
        final_yaml = generate_yaml(proxies, rules_content)

        st.success(f"ğŸ‰ è½¬æ¢æˆåŠŸï¼å…±åŒ…å« {len(proxies)} ä¸ªèŠ‚ç‚¹ã€‚")

        st.download_button(
            label="ä¸‹è½½ config.yaml",
            data=final_yaml,
            file_name="config.yaml",
            mime="text/yaml"
        )

        with st.expander("é¢„è§ˆç”Ÿæˆçš„å†…å®¹"):
            st.code(final_yaml, language="yaml")
