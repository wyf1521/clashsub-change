import streamlit as st
import json
import base64
import urllib.parse
import os
import requests
import uuid


ALLOWED_PREFIXES = ("vmess://", "vless://", "hysteria2://", "tuic://")


def safe_base64_decode(s: str) -> str:
    """å®‰å…¨çš„ Base64 è§£ç ï¼Œå¤„ç†å¡«å……å’Œæ›¿æ¢ï¼›å¤±è´¥åˆ™è¿”å›åŸå­—ç¬¦ä¸²"""
    if not s:
        return ""
    s = s.strip().replace("-", "+").replace("_", "/")
    missing_padding = len(s) % 4
    if missing_padding:
        s += "=" * (4 - missing_padding)
    try:
        return base64.urlsafe_b64decode(s).decode("utf-8")
    except Exception:
        try:
            return base64.b64decode(s).decode("utf-8")
        except Exception:
            return s


def safe_name_decode(name: str) -> str:
    if not name:
        return "Unknown_Node"
    try:
        decoded = urllib.parse.unquote(name)
        decoded = urllib.parse.unquote(decoded)
        return decoded
    except Exception:
        return name


def normalize_nodes_text(text: str) -> str:
    """æŠŠè®¢é˜…é‡Œå¸¸è§çš„ | åˆ†éš”ä¹Ÿç»Ÿä¸€æˆæ¢è¡Œï¼Œæ–¹ä¾¿åç»­é€è¡Œå¤„ç†"""
    if not text:
        return ""
    return text.replace("|", "\n")


def filter_valid_nodes_lines(text: str):
    """
    è¿‡æ»¤ + ç»Ÿè®¡ï¼š
    - valid_linesï¼šåˆæ³•è¡Œï¼ˆéç©ºä¸”ä»¥å…è®¸åè®®å¼€å¤´ï¼‰
    - invalidsï¼šéæ³•è¡Œ (è¡Œå·, å†…å®¹)
    - statsï¼šç»Ÿè®¡ä¿¡æ¯
    """
    valid_lines = []
    invalids = []

    total_nonempty = 0
    proto_count = {"vmess": 0, "vless": 0, "hysteria2": 0, "tuic": 0}

    for idx, raw in enumerate(text.splitlines(), start=1):
        line = raw.strip()
        if not line:
            continue
        total_nonempty += 1

        if line.startswith("vmess://"):
            proto_count["vmess"] += 1
            valid_lines.append(line)
        elif line.startswith("vless://"):
            proto_count["vless"] += 1
            valid_lines.append(line)
        elif line.startswith("hysteria2://"):
            proto_count["hysteria2"] += 1
            valid_lines.append(line)
        elif line.startswith("tuic://"):
            proto_count["tuic"] += 1
            valid_lines.append(line)
        else:
            invalids.append((idx, line))

    stats = {
        "total_nonempty": total_nonempty,
        "valid": len(valid_lines),
        "invalid": len(invalids),
        "proto_count": proto_count,
    }
    return valid_lines, invalids, stats


def dedupe_lines_keep_first(lines):
    """
    å»é‡ï¼šæŒ‰æ•´è¡Œå»é‡ï¼ˆstrip åï¼‰
    - è¿”å›ï¼šdeduped_lines, dup_count
    """
    seen = set()
    deduped = []
    dup_count = 0
    for line in lines:
        key = line.strip()
        if not key:
            continue
        if key in seen:
            dup_count += 1
            continue
        seen.add(key)
        deduped.append(line)
    return deduped, dup_count


def parse_vmess(url_body: str):
    try:
        json_str = safe_base64_decode(url_body)
        data = json.loads(json_str)

        raw_name = data.get("ps", "vmess")
        name = safe_name_decode(raw_name)

        proxy = {
            "name": name,
            "type": "vmess",
            "server": data.get("add"),
            "port": int(data.get("port")),
            "uuid": data.get("id"),
            "alterId": int(data.get("aid", 0)),
            "cipher": data.get("scy", "auto"),
            "network": data.get("net", "ws"),
            "tls": True if data.get("tls") == "tls" or data.get("tls") is True else False,
            "udp": True,
            "skip-cert-verify": True if data.get("verify_cert") is False else False,
        }
        if proxy["network"] == "ws":
            proxy["ws-opts"] = {
                "path": data.get("path", "/"),
                "headers": {"Host": data.get("host", data.get("add"))},
            }
        return proxy
    except Exception:
        return None


def parse_vless(parsed_url):
    params = urllib.parse.parse_qs(parsed_url.query)
    network = params.get("type", ["tcp"])[0]

    raw_name = parsed_url.fragment
    name = safe_name_decode(raw_name) if raw_name else "vless_node"

    proxy = {
        "name": name,
        "type": "vless",
        "server": parsed_url.hostname,
        "port": parsed_url.port,
        "uuid": parsed_url.username,
        "udp": True,
        "tls": True,
        "network": network,
        "servername": params.get("sni", [""])[0],
        "skip-cert-verify": True if params.get("allowInsecure", ["0"])[0] == "1" else False,
    }
    if network == "ws":
        host = params.get("host", [""])[0]
        if not host:
            host = proxy["servername"] or proxy["server"]
        proxy["ws-opts"] = {
            "path": params.get("path", ["/"])[0],
            "headers": {"Host": host},
        }
    if network == "tcp":
        flow = params.get("flow", [""])[0]
        if flow:
            proxy["flow"] = flow
    if "fp" in params:
        proxy["client-fingerprint"] = params["fp"][0]
    else:
        proxy["client-fingerprint"] = "chrome"
    if params.get("security", [""])[0] == "reality":
        proxy["reality-opts"] = {"public-key": params.get("pbk", [""])[0]}
        sid = params.get("sid", params.get("shortId", params.get("short-id", [])))
        if sid:
            proxy["reality-opts"]["short-id"] = sid[0]
        if not proxy["servername"]:
            proxy["servername"] = params.get("sni", [""])[0]
    return proxy


def parse_hysteria2(parsed_url):
    params = urllib.parse.parse_qs(parsed_url.query)
    name = safe_name_decode(parsed_url.fragment) if parsed_url.fragment else "hysteria2_node"
    return {
        "name": name,
        "type": "hysteria2",
        "server": parsed_url.hostname,
        "port": parsed_url.port,
        "password": parsed_url.username,
        "sni": params.get("sni", [""])[0],
        "skip-cert-verify": True if params.get("insecure", ["0"])[0] == "1" else False,
        "udp": True,
    }


def parse_tuic(parsed_url):
    params = urllib.parse.parse_qs(parsed_url.query)
    user_info = parsed_url.username.split(":") if parsed_url.username else ["", ""]
    name = safe_name_decode(parsed_url.fragment) if parsed_url.fragment else "tuic_node"
    proxy = {
        "name": name,
        "type": "tuic",
        "server": parsed_url.hostname,
        "port": parsed_url.port,
        "uuid": user_info[0],
        "password": user_info[1] if len(user_info) > 1 else "",
        "sni": params.get("sni", [""])[0],
        "udp-relay-mode": "native",
        "congestion-controller": params.get("congestion_control", ["bbr"])[0],
        "skip-cert-verify": True if params.get("insecure", ["0"])[0] == "1" else False,
        "disable-sni": True,
        "udp": True,
    }
    if "alpn" in params:
        proxy["alpn"] = [params["alpn"][0]]
    return proxy


def generate_yaml(proxies, rules_content, source_url=""):
    proxy_names = []
    for p in proxies:
        safe_n = p["name"].replace('"', "").replace("'", "").strip()
        p["name"] = safe_n
        proxy_names.append(safe_n)

    header_info = f"# Source Subscription: {source_url}\n" if source_url else ""
    yaml_content = f"""{header_info}mixed-port: 7890
allow-lan: true
mode: Rule
log-level: info
external-controller: :9090
proxies:
"""
    for p in proxies:
        yaml_content += f'  - name: "{p["name"]}"\n'
        yaml_content += f"    type: {p['type']}\n"
        yaml_content += f"    server: {p['server']}\n"
        yaml_content += f"    port: {p['port']}\n"
        for key in [
            "uuid",
            "password",
            "udp",
            "tls",
            "flow",
            "servername",
            "sni",
            "client-fingerprint",
            "network",
            "alterId",
            "cipher",
            "skip-cert-verify",
            "udp-relay-mode",
            "congestion-controller",
            "disable-sni",
        ]:
            if key in p:
                val = str(p[key]).lower() if isinstance(p[key], bool) else p[key]
                yaml_content += f"    {key}: {val}\n"

        if "ws-opts" in p:
            yaml_content += (
                "    ws-opts:\n"
                f'      path: "{p["ws-opts"]["path"]}"\n'
                "      headers:\n"
                f'        Host: {p["ws-opts"]["headers"]["Host"]}\n'
            )
        if "reality-opts" in p:
            yaml_content += "    reality-opts:\n"
            yaml_content += f'      public-key: {p["reality-opts"]["public-key"]}\n'
            if "short-id" in p["reality-opts"]:
                yaml_content += f'      short-id: {p["reality-opts"]["short-id"]}\n'
        if "alpn" in p:
            yaml_content += "    alpn:\n"
            for a in p["alpn"]:
                yaml_content += f"      - {a}\n"

    yaml_content += "proxy-groups:\n"

    groups = [
        {"name": "ğŸš€ èŠ‚ç‚¹é€‰æ‹©", "type": "select", "special": ["â™»ï¸ è‡ªåŠ¨é€‰æ‹©", "DIRECT"]},
        {
            "name": "â™»ï¸ è‡ªåŠ¨é€‰æ‹©",
            "type": "url-test",
            "url": "http://www.gstatic.com/generate_204",
            "interval": 300,
            "tolerance": 50,
            "special": [],
        },
        {"name": "ğŸŒ å›½å¤–åª’ä½“", "type": "select", "special": ["ğŸš€ èŠ‚ç‚¹é€‰æ‹©", "â™»ï¸ è‡ªåŠ¨é€‰æ‹©", "ğŸ¯ å…¨çƒç›´è¿"]},
        {"name": "ğŸ“² ç”µæŠ¥ä¿¡æ¯", "type": "select", "special": ["ğŸš€ èŠ‚ç‚¹é€‰æ‹©", "ğŸ¯ å…¨çƒç›´è¿"]},
        {"name": "â“‚ï¸ å¾®è½¯æœåŠ¡", "type": "select", "special": ["ğŸ¯ å…¨çƒç›´è¿", "ğŸš€ èŠ‚ç‚¹é€‰æ‹©"]},
        {"name": "ğŸ è‹¹æœæœåŠ¡", "type": "select", "special": ["ğŸš€ èŠ‚ç‚¹é€‰æ‹©", "ğŸ¯ å…¨çƒç›´è¿"]},
        {"name": "ğŸ“¢ è°·æ­ŒFCM", "type": "select", "special": ["ğŸš€ èŠ‚ç‚¹é€‰æ‹©", "ğŸ¯ å…¨çƒç›´è¿", "â™»ï¸ è‡ªåŠ¨é€‰æ‹©"]},
        {"name": "ğŸ¯ å…¨çƒç›´è¿", "type": "select", "base": ["DIRECT", "ğŸš€ èŠ‚ç‚¹é€‰æ‹©", "â™»ï¸ è‡ªåŠ¨é€‰æ‹©"], "no_proxies": True},
        {"name": "ğŸ›‘ å…¨çƒæ‹¦æˆª", "type": "select", "base": ["REJECT", "DIRECT"], "no_proxies": True},
        {"name": "ğŸƒ åº”ç”¨å‡€åŒ–", "type": "select", "base": ["REJECT", "DIRECT"], "no_proxies": True},
        {"name": "ğŸŸ æ¼ç½‘ä¹‹é±¼", "type": "select", "special": ["ğŸš€ èŠ‚ç‚¹é€‰æ‹©", "ğŸ¯ å…¨çƒç›´è¿", "â™»ï¸ è‡ªåŠ¨é€‰æ‹©"]},
    ]

    for g in groups:
        yaml_content += f'  - name: "{g["name"]}"\n'
        yaml_content += f"    type: {g['type']}\n"
        if "url" in g:
            yaml_content += f"    url: {g['url']}\n"
            yaml_content += f"    interval: {g['interval']}\n"
            yaml_content += f"    tolerance: {g['tolerance']}\n"

        yaml_content += "    proxies:\n"
        if "base" in g:
            for b in g["base"]:
                yaml_content += f'      - "{b}"\n'
        if "special" in g:
            for s in g["special"]:
                yaml_content += f'      - "{s}"\n'
        if not g.get("no_proxies", False):
            for name in proxy_names:
                yaml_content += f'      - "{name}"\n'

    yaml_content += "rules:\n" + rules_content
    return yaml_content


# ================= ç½‘é¡µç•Œé¢é€»è¾‘ =================

st.set_page_config(page_title="V2Ray è½¬ Clash", page_icon="ğŸ”„", layout="centered")

# ===== GitHub é¡¹ç›®å…¥å£ï¼ˆä¾§è¾¹æ ï¼‰=====
st.sidebar.markdown("## é¡¹ç›®åœ°å€")
st.sidebar.markdown(
    """
    <a href="https://github.com/wyf1521/clashsub-change" target="_blank"
       style="display:flex;align-items:center;gap:8px;text-decoration:none;">
      <img src="https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png" width="20">
      <span>wyf1521 / clashsub-change</span>
    </a>
    """,
    unsafe_allow_html=True,
)
st.sidebar.link_button("æ‰“å¼€ GitHub", "https://github.com/wyf1521/clashsub-change")

st.title("ğŸ”„ V2Ray é“¾æ¥è½¬ Clash Meta é…ç½®")
st.markdown("---")

col1, col2 = st.columns(2)
with col1:
    nodes_files = st.file_uploader("1. ä¸Šä¼ èŠ‚ç‚¹æ–‡ä»¶ (txtï¼Œå¯å¤šé€‰)", type=["txt"], accept_multiple_files=True)
with col2:
    rules_file = st.file_uploader("2. ä¸Šä¼ è§„åˆ™æ–‡ä»¶ (å¯é€‰)", type=["txt"])

manual_nodes_text = st.text_area(
    "ğŸ§¾ æ‰‹åŠ¨ç²˜è´´èŠ‚ç‚¹å†…å®¹ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼›æ¯è¡Œä¸€ä¸ªé“¾æ¥ï¼Œä»…æ”¯æŒ vmess/vless/hysteria2/tuicï¼‰",
    placeholder="hysteria2://...\ntuic://...\nvmess://...\nvless://...",
    height=180,
)

subscription_urls_text = st.text_area(
    "ğŸ”— è¾“å…¥è®¢é˜…é“¾æ¥ï¼ˆä¼˜å…ˆçº§æœ€ä½ï¼›å¯å¤šè¡Œï¼Œæ¯è¡Œä¸€ä¸ªï¼‰",
    placeholder="https://example.com/sub/...\nhttps://example2.com/sub/...",
    height=120,
)
subscription_urls = [u.strip() for u in subscription_urls_text.splitlines() if u.strip()]

# æ³¨æ„ï¼šè¯·ç¡®ä¿æœåŠ¡å™¨å·²é…ç½®é™æ€æ–‡ä»¶æœåŠ¡
server_host = "http://ip.padaro.top:8501"

if st.button("å¼€å§‹è½¬æ¢", type="primary", use_container_width=True):
    sources = []
    contents = []

    # =========================================================
    # é¡ºåºè¦æ±‚ï¼šæ‰‹åŠ¨è¾“å…¥ï¼ˆæœ€å‰ï¼‰ -> ä¸Šä¼ æ–‡ä»¶ï¼ˆå…¶æ¬¡ï¼‰ -> è®¢é˜…ç½‘å€ï¼ˆæœ€åï¼‰
    # =========================================================

    # --- 1) æ‰‹åŠ¨ç²˜è´´ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰---
    if manual_nodes_text and manual_nodes_text.strip():
        text = normalize_nodes_text(manual_nodes_text)
        sources.append("manual_input")
        contents.append(text)

    # --- 2) ä¸Šä¼ æ–‡ä»¶ï¼ˆå…¶æ¬¡ï¼‰---
    if nodes_files:
        for f in nodes_files:
            try:
                text = f.getvalue().decode("utf-8", errors="ignore")
                text = normalize_nodes_text(text)
                if text.strip():
                    sources.append(f.name)
                    contents.append(text)
            except Exception as e:
                st.error(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥ï¼š{f.name}\nåŸå› ï¼š{e}")

    # --- 3) è®¢é˜…é“¾æ¥ï¼ˆæœ€åï¼‰---
    for url in subscription_urls:
        try:
            with st.spinner(f"ğŸš€ æ­£åœ¨è¯·æ±‚è®¢é˜…ï¼š{url}"):
                headers = {
                    "User-Agent": (
                        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                        "AppleWebKit/537.36 (KHTML, like Gecko) "
                        "Chrome/120.0.0.0 Safari/537.36"
                    )
                }
                resp = requests.get(url, headers=headers, timeout=15)
                resp.raise_for_status()
                raw_content = resp.text.strip()

                decoded = safe_base64_decode(raw_content)

                decoded_n = normalize_nodes_text(decoded)
                raw_n = normalize_nodes_text(raw_content)

                # é€‰æ‹©â€œæ›´åƒèŠ‚ç‚¹åˆ—è¡¨â€çš„é‚£ä¸ª
                if any(p in decoded_n for p in ALLOWED_PREFIXES):
                    text = decoded_n
                else:
                    text = raw_n

                if text.strip():
                    sources.append(url)
                    contents.append(text)
        except Exception as e:
            st.error(f"âŒ è·å–è®¢é˜…å¤±è´¥ï¼š{url}\nåŸå› ï¼š{e}")

    if not contents:
        st.warning("âš ï¸ è¯·è‡³å°‘ç²˜è´´èŠ‚ç‚¹å†…å®¹ã€ä¸Šä¼ èŠ‚ç‚¹æ–‡ä»¶ï¼Œæˆ–è¾“å…¥è®¢é˜…é“¾æ¥ï¼")
        st.stop()

    # åˆå¹¶ï¼ˆæŒ‰ä¸Šé¢ append çš„é¡ºåºï¼‰
    nodes_content_raw = "\n".join(contents).strip()
    current_source = " | ".join(sources)

    # --- è¿‡æ»¤éæ³•è¡Œï¼ˆè·³è¿‡ + ç»Ÿè®¡ + æç¤ºï¼‰---
    valid_lines, invalids, stats = filter_valid_nodes_lines(nodes_content_raw)

    # --- å»é‡ï¼šä¿ç•™ç¬¬ä¸€æ¬¡å‡ºç°ï¼ˆå› æ­¤ä¼˜å…ˆçº§è‡ªç„¶æˆç«‹ï¼‰---
    deduped_lines, dup_count = dedupe_lines_keep_first(valid_lines)

    # UI ç»Ÿè®¡
    st.info(
        f"ğŸ“Š è¾“å…¥ç»Ÿè®¡ï¼šéç©ºè¡Œ {stats['total_nonempty']}ï¼Œæœ‰æ•ˆ {stats['valid']}ï¼Œè·³è¿‡ {stats['invalid']}ï¼Œå»é‡ä¸¢å¼ƒ {dup_count}ã€‚\n"
        f"åè®®åˆ†å¸ƒï¼švmess {stats['proto_count']['vmess']} / "
        f"vless {stats['proto_count']['vless']} / "
        f"hysteria2 {stats['proto_count']['hysteria2']} / "
        f"tuic {stats['proto_count']['tuic']}"
    )

    if invalids:
        show_n = 20
        preview = "\n".join([f"ç¬¬ {ln} è¡Œï¼š{txt[:200]}" for ln, txt in invalids[:show_n]])
        st.warning("âš ï¸ å·²è·³è¿‡ä¸æ”¯æŒçš„è¡Œï¼ˆåªä¿ç•™ vmess/vless/hysteria2/tuic å¼€å¤´çš„è¡Œï¼‰")
        st.code(preview, language="text")
        if len(invalids) > show_n:
            st.caption(f"ä»…å±•ç¤ºå‰ {show_n} æ¡ï¼Œå…± {len(invalids)} æ¡è¢«è·³è¿‡ã€‚")

    if dup_count > 0:
        st.warning(f"â™»ï¸ å·²å»é‡ï¼šå‘ç°å¹¶ä¸¢å¼ƒ {dup_count} æ¡é‡å¤èŠ‚ç‚¹è¡Œï¼ˆä¿ç•™ä¼˜å…ˆçº§æ›´é«˜çš„é¦–æ¬¡å‡ºç°ï¼‰ã€‚")

    if not deduped_lines:
        st.error("âŒ æ²¡æœ‰ä»»ä½•æœ‰æ•ˆèŠ‚ç‚¹è¡Œï¼ˆå…¨éƒ¨è¢«è·³è¿‡æˆ–ä¸ºç©ºï¼‰ï¼Œè¯·æ£€æŸ¥è¾“å…¥ã€‚")
        st.stop()

    nodes_content = "\n".join(deduped_lines)

    # --- è¯»å–è§„åˆ™æ–‡ä»¶ ---
    rules_content = ""
    if rules_file:
        rules_content = rules_file.getvalue().decode("utf-8", errors="ignore")
    elif os.path.exists("rules.txt"):
        try:
            with open("rules.txt", "r", encoding="utf-8") as f:
                rules_content = f.read()
        except Exception:
            rules_content = ""

    # --- è§£æèŠ‚ç‚¹ï¼ˆé¡ºåº = nodes_content é¡ºåºï¼‰---
    proxies = []
    name_counter = {}

    for line in nodes_content.splitlines():
        line = line.strip()
        if not line:
            continue

        p = None
        try:
            if line.startswith("vmess://"):
                p = parse_vmess(line[8:])
            elif line.startswith("vless://"):
                p = parse_vless(urllib.parse.urlparse(line))
            elif line.startswith("hysteria2://"):
                p = parse_hysteria2(urllib.parse.urlparse(line))
            elif line.startswith("tuic://"):
                p = parse_tuic(urllib.parse.urlparse(line))

            if p:
                o_name = p["name"]
                if o_name in name_counter:
                    name_counter[o_name] += 1
                    p["name"] = f"{o_name}_{name_counter[o_name]}"
                else:
                    name_counter[o_name] = 0
                proxies.append(p)
        except Exception:
            continue

    if not proxies:
        st.error("âŒ æœªè¯†åˆ«åˆ°æœ‰æ•ˆèŠ‚ç‚¹ï¼Œè¯·æ£€æŸ¥é“¾æ¥æ ¼å¼")
    else:
        final_yaml = generate_yaml(proxies, rules_content, current_source)

        static_dir = "static"
        if not os.path.exists(static_dir):
            os.makedirs(static_dir)

        random_filename = f"config_{uuid.uuid4().hex[:8]}.yaml"
        file_path = os.path.join(static_dir, random_filename)

        with open(file_path, "w", encoding="utf-8-sig") as f:
            f.write(final_yaml)

        download_url = f"{server_host}/app/static/{random_filename}"

        st.success(f"ğŸ‰ è½¬æ¢æˆåŠŸï¼å…±åŒ…å« {len(proxies)} ä¸ªèŠ‚ç‚¹")
        st.markdown("---")

        st.markdown("### ğŸ“‹ è®¢é˜…é“¾æ¥")
        st.info("è¯·å…¨é€‰ä¸‹æ–¹çš„é“¾æ¥è¿›è¡Œå¤åˆ¶ï¼š")

        st.text_input("è®¢é˜… URL", value=download_url)

        st.download_button(
            label="ğŸ“¥ ä¸‹è½½ YAML é…ç½®æ–‡ä»¶",
            data=final_yaml,
            file_name="clash_config.yaml",
            mime="text/yaml",
        )
